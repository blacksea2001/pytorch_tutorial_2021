{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd04a14f160a788381b942a00c7818b6b2d1b1e565aaa187944793ce39ed61a647c",
   "display_name": "Python 3.6.12 64-bit ('transformer': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Save and load model\n",
    "\n",
    "當保存和加載模型時，需要熟悉三個核心功能：\n",
    "\n",
    "1. ``torch.save``：將序列化對象保存到硬碟。此函數使用Python的pickle模組進行序列化。使用此函數可以保存如模型、tensor、字典等各種對象\n",
    "2. ``torch.load``：使用pickle的unpickling功能將pickle對象文件反序列化到記憶體。此功能還可以有助於設備加載數據\n",
    "3. ``torch.nn.Module.load_state_dict``：使用反序列化函數 state_dict 來加載模型的參數字典"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## state_dict\n",
    "\n",
    "* ``torch.nn.Module``模型的可學習參數（即權重和偏差）包含在模型的參數中，（使用model.parameters()可以進行訪問）\n",
    "\n",
    "* ``state_dict``是Python字典對象，它將每一層映射到其參數張量。注意，只有具有可學習參數的層（如卷積層，線性層等）的模型才具有state_dict這一項。目標優化torch.optim也有state_dict屬性，它包含有關優化器的狀態訊息，以及使用的超參數。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model's state_dict:\nconv1.weight \t torch.Size([6, 3, 5, 5])\nconv1.bias \t torch.Size([6])\nconv2.weight \t torch.Size([16, 6, 5, 5])\nconv2.bias \t torch.Size([16])\nfc1.weight \t torch.Size([120, 400])\nfc1.bias \t torch.Size([120])\nfc2.weight \t torch.Size([84, 120])\nfc2.bias \t torch.Size([84])\nfc3.weight \t torch.Size([10, 84])\nfc3.bias \t torch.Size([10])\n\n\nOptimizer's state_dict:\nstate \t {}\nparam_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define model\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "print('\\n')\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "source": [
    "## Save/Load ``state_dict`` (Recommended)\n",
    "\n",
    "* 保存好模型用來推斷的時候，只需要保存模型學習到的參數，使用torch.save()函數來保存模型state_dict，給模型恢復提供最大的靈活性\n",
    "\n",
    "* 在 PyTorch 中最常見的模型保存使``.pt``或者是``.pth``\n",
    "\n",
    "* 在運行推理之前，務必調用model.eval()去設置 dropout 和 batch normalization 層為評估模式。如果不這麼做，可能導致模型推斷結果不一致"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "source": [
    "## Save/Load Entire Model\n",
    "\n",
    "* 此部分保存/加載過程使用最直觀的語法並涉及最少量的程式碼。以 Python ``pickle`` 模組來保存模型。這種方法的缺點是序列化數據受限於某種特殊的類而且需要確切的字典結構。這是因為pickle無法保存模型類本身。相反，它保存包含類的文件的路徑，該文件在加載時使用。因此，當在其他項目使用或者重構之後，你的程式碼可能會以各種方式中斷"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "# Model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "source": [
    "# 其他方式參考官網 [https://pytorch.org/tutorials/beginner/saving_loading_models.html]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}